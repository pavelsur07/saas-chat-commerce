parameters:
    ai.suggestions.model: 'gpt-4o-mini'      # можно поменять
    ai.suggestions.temperature: 0.7
    ai.suggestions.max_history: 16           # последние N сообщений
    ai.suggestions.max_chars: 4000           # safety-ограничение контекста
    ai.suggestions.timeout_seconds: 10
    ai.suggestions.rate_limit_seconds: 3    # ← окно rate-limit на диалог
    ai.suggestions.max_company_context_chars: '%env(int:AI_MAX_CONTEXT_CHARS)%'
    ai.provider: '%env(string:AI_PROVIDER)%'

services:
    # провайдер мок
    App\Service\AI\Provider\MockLlmClient: ~

    # селектор провайдера (mock/openai)
    App\Service\AI\LlmClientSelector:
        arguments:
            $provider: '%ai.provider%'
            # $mock подставится автоворингом по типу, но можно явно:
            # $mock: '@App\Service\AI\Provider\MockLlmClient'

    # логирующий враппер ДОЛЖЕН получать селектор как inner
    App\Service\AI\LlmClientWithLogging:
        arguments:
            $inner: '@App\Service\AI\LlmClientSelector'

    # ИМЕННО так: наружу даём интерфейс -> логгер
    App\Service\AI\LlmClient: '@App\Service\AI\LlmClientWithLogging'

